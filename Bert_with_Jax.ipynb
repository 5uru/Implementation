{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-02T17:25:59.974454Z",
     "start_time": "2025-03-02T17:25:59.944366Z"
    }
   },
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.nn.initializers import normal as normal_init\n",
    "from flax.training import train_state\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "from transformers import BertTokenizer\n",
    "from jax import random"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Hyperparameters",
   "id": "7d46794c773ba5c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T17:30:48.798841Z",
     "start_time": "2025-03-02T17:30:48.793082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "enc_layers = 6\n",
    "head_count = 12\n",
    "emb_size = 384 # from 12\n",
    "seq_len = 36\n",
    "drop_rate = 0.1"
   ],
   "id": "a7c099c709e378d0",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get the data",
   "id": "1507281f62267a2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T11:16:16.827706Z",
     "start_time": "2025-03-02T11:16:14.416443Z"
    }
   },
   "cell_type": "code",
   "source": "!wget -O input.txt https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt",
   "id": "fdca2c506503d867",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-02 12:16:14--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1115394 (1.1M) [text/plain]\r\n",
      "Saving to: ‘input.txt’\r\n",
      "\r\n",
      "input.txt           100%[===================>]   1.06M  1.10MB/s    in 1.0s    \r\n",
      "\r\n",
      "2025-03-02 12:16:16 (1.10 MB/s) - ‘input.txt’ saved [1115394/1115394]\r\n",
      "\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T11:16:30.697467Z",
     "start_time": "2025-03-02T11:16:30.692753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "with open('input.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "print(len(data))"
   ],
   "id": "37191de45f04f822",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T11:16:42.900573Z",
     "start_time": "2025-03-02T11:16:42.897951Z"
    }
   },
   "cell_type": "code",
   "source": "print(data[:100])",
   "id": "8c50a1abf432856b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T11:19:04.468495Z",
     "start_time": "2025-03-02T11:19:04.451368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into lines\n",
    "lines = data.splitlines()\n",
    "lines[:10]"
   ],
   "id": "f769b346a20b6053",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Citizen:',\n",
       " 'Before we proceed any further, hear me speak.',\n",
       " '',\n",
       " 'All:',\n",
       " 'Speak, speak.',\n",
       " '',\n",
       " 'First Citizen:',\n",
       " 'You are all resolved rather to die than to famish?',\n",
       " '',\n",
       " 'All:']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T11:19:04.611073Z",
     "start_time": "2025-03-02T11:19:04.604828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove empty lines\n",
    "no_sp_lines = []\n",
    "for elem in lines:\n",
    "    if elem != '':\n",
    "        no_sp_lines.append(elem)\n",
    "    else:\n",
    "        continue"
   ],
   "id": "876eb9ed963a8293",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T11:19:04.773535Z",
     "start_time": "2025-03-02T11:19:04.770026Z"
    }
   },
   "cell_type": "code",
   "source": "no_sp_lines[:5]\n",
   "id": "aba71947af2a41ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Citizen:',\n",
       " 'Before we proceed any further, hear me speak.',\n",
       " 'All:',\n",
       " 'Speak, speak.',\n",
       " 'First Citizen:']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T11:19:05.018472Z",
     "start_time": "2025-03-02T11:19:05.010118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Concatenate lines that end with ':'\n",
    "cat_lines = []\n",
    "i = 0\n",
    "\n",
    "while i < len(no_sp_lines):\n",
    "    if no_sp_lines[i].endswith(':'):\n",
    "        x = no_sp_lines[i] + ' ' + no_sp_lines[i + 1]\n",
    "        cat_lines.append(x)\n",
    "        i += 2\n",
    "    else:\n",
    "        cat_lines.append(no_sp_lines[i])\n",
    "        i += 1"
   ],
   "id": "9ae2ac5d1f457029",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T11:19:08.382106Z",
     "start_time": "2025-03-02T11:19:08.379163Z"
    }
   },
   "cell_type": "code",
   "source": "cat_lines[:30]",
   "id": "908f5a01719ec975",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Citizen: Before we proceed any further, hear me speak.',\n",
       " 'All: Speak, speak.',\n",
       " 'First Citizen: You are all resolved rather to die than to famish?',\n",
       " 'All: Resolved. resolved.',\n",
       " 'First Citizen: First, you know Caius Marcius is chief enemy to the people.',\n",
       " \"All: We know't, we know't.\",\n",
       " \"First Citizen: Let us kill him, and we'll have corn at our own price.\",\n",
       " \"Is't a verdict?\",\n",
       " \"All: No more talking on't; let it be done: away, away!\",\n",
       " 'Second Citizen: One word, good citizens.',\n",
       " 'First Citizen: We are accounted poor citizens, the patricians good.',\n",
       " 'What authority surfeits on would relieve us: if they',\n",
       " 'would yield us but the superfluity, while it were',\n",
       " 'wholesome, we might guess they relieved us humanely;',\n",
       " 'but they think we are too dear: the leanness that',\n",
       " 'afflicts us, the object of our misery, is as an',\n",
       " 'inventory to particularise their abundance; our',\n",
       " 'sufferance is a gain to them Let us revenge this with',\n",
       " 'our pikes, ere we become rakes: for the gods know I',\n",
       " 'speak this in hunger for bread, not in thirst for revenge.',\n",
       " 'Second Citizen: Would you proceed especially against Caius Marcius?',\n",
       " \"All: Against him first: he's a very dog to the commonalty.\",\n",
       " 'Second Citizen: Consider you what services he has done for his country?',\n",
       " 'First Citizen: Very well; and could be content to give him good',\n",
       " 'report fort, but that he pays himself with being proud.',\n",
       " 'Second Citizen: Nay, but speak not maliciously.',\n",
       " 'First Citizen: I say unto you, what he hath done famously, he did',\n",
       " 'it to that end: though soft-conscienced men can be',\n",
       " 'content to say it was for his country he did it to',\n",
       " 'please his mother and to be partly proud; which he']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tokenizers",
   "id": "9630c5cccded2153"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T12:50:22.397603Z",
     "start_time": "2025-03-02T12:50:10.772562Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')",
   "id": "41dffdfd03adf9cc",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T12:50:26.122129Z",
     "start_time": "2025-03-02T12:50:26.119675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Special tokens\n",
    "print(\"Special Tokens:\")\n",
    "print(\"CLS:\", tokenizer.cls_token)\n",
    "print(\"SEP:\", tokenizer.sep_token)\n",
    "print(\"PAD:\", tokenizer.pad_token)\n",
    "print(\"MASK:\", tokenizer.mask_token)\n",
    "print(\"UNK:\", tokenizer.unk_token)"
   ],
   "id": "2d2ad85bafdbe2af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special Tokens:\n",
      "CLS: [CLS]\n",
      "SEP: [SEP]\n",
      "PAD: [PAD]\n",
      "MASK: [MASK]\n",
      "UNK: [UNK]\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T12:50:45.589560Z",
     "start_time": "2025-03-02T12:50:42.302372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence = \"To be, or not to be.\"\n",
    "encoded = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "\n",
    "print(\"\\nEncoded with special tokens:\", encoded)\n",
    "print(\"Decoded back:\", tokenizer.decode(encoded))"
   ],
   "id": "19480ade3ba0e662",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded with special tokens: [101, 2000, 2022, 1010, 2030, 2025, 2000, 2022, 1012, 102]\n",
      "Decoded back: [CLS] to be, or not to be. [SEP]\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T17:37:50.326065Z",
     "start_time": "2025-03-02T17:37:50.316787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def masker(encoded_text, key):\n",
    "    masking_prob = 0.15\n",
    "    masked_input_ids = encoded_text.clone()  # Make sure we don't modify the original tensor\n",
    "    labels = encoded_text.clone()  # Same for labels\n",
    "\n",
    "    for i in range(len(encoded_text)):\n",
    "        if jax.random.uniform(key, minval=0, maxval=1) < masking_prob and masked_input_ids[i] not in tokenizer.all_special_ids:\n",
    "            # Replace with [MASK] 80% of the time\n",
    "            if jax.random.uniform(key, minval=0, maxval=1) < 0.8:\n",
    "                masked_input_ids[i] = tokenizer.mask_token_id\n",
    "            # Replace with a random token 10% of the time\n",
    "            elif jax.random.uniform(key, minval=0, maxval=1) < 0.9:\n",
    "                masked_input_ids[i] = random.randint(key,shape=(1,),minval=0, maxval=tokenizer.vocab_size - 1)\n",
    "            # Keep the original word 10% of the time\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    # Set the labels to -100 for the positions that were masked\n",
    "    #labels[masked_input_ids == tokenizer.mask_token_id] = -100\n",
    "    return masked_input_ids, labels#"
   ],
   "id": "988c8de6d5bd34f2",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T17:37:56.181512Z",
     "start_time": "2025-03-02T17:37:50.808041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_encoded = tokenizer(\n",
    "        cat_lines,\n",
    "        padding='max_length',\n",
    "        #truncation=True,\n",
    "        max_length=36,\n",
    "        return_tensors=\"jax\"\n",
    ")\n"
   ],
   "id": "6d1545930faa89fd",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T17:37:56.205169Z",
     "start_time": "2025-03-02T17:37:56.201826Z"
    }
   },
   "cell_type": "code",
   "source": "test_encoded['input_ids'][0]",
   "id": "89e0856917fa37e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([  101,  2034,  6926,  1024,  2077,  2057, 10838,  2151,  2582,\n",
       "        1010,  2963,  2033,  3713,  1012,   102,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0],      dtype=int32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T17:45:43.499721Z",
     "start_time": "2025-03-02T17:45:43.489432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BidirectionalSelfAttention(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        query = nn.Dense(emb_size, use_bias=False)(x)\n",
    "        key = nn.Dense(emb_size, use_bias=False)(x)\n",
    "        value = nn.Dense(emb_size, use_bias=False)(x)\n",
    "\n",
    "        attention_scores = jnp.matmul(query, key.T)\n",
    "        attention_weights = jax.nn.softmax(attention_scores / key.shape[-1]**0.5, axis=-1)\n",
    "        context_vector = jnp.matmul(attention_weights, value)\n",
    "        return context_vector\n"
   ],
   "id": "9c20594a90a02a57",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T18:40:34.137696Z",
     "start_time": "2025-03-02T18:40:34.128957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    head_dim: int = emb_size // head_count\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, train=True):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = nn.Dense(emb_size, use_bias=False)(x)\n",
    "        queries = nn.Dense(emb_size, use_bias=False)(x)\n",
    "        values = nn.Dense(emb_size, use_bias=False)(x)\n",
    "\n",
    "        # Reshape to separate the head dimension\n",
    "        keys = keys.reshape(b, num_tokens, head_count, self.head_dim)\n",
    "        values = values.reshape(b, num_tokens, head_count, self.head_dim)\n",
    "        queries = queries.reshape(b, num_tokens, head_count, self.head_dim)\n",
    "\n",
    "        # Transpose for attention computation\n",
    "        keys = jnp.transpose(keys, (0, 2, 1, 3))      # [b, h, n, d]\n",
    "        values = jnp.transpose(values, (0, 2, 1, 3))  # [b, h, n, d]\n",
    "        queries = jnp.transpose(queries, (0, 2, 1, 3)) # [b, h, n, d]\n",
    "\n",
    "        # Compute attention scores\n",
    "        attn_scores = jnp.matmul(queries, jnp.transpose(keys, (0, 1, 3, 2)))\n",
    "        attn_weights = jax.nn.softmax(attn_scores / jnp.sqrt(self.head_dim), axis=-1)\n",
    "\n",
    "        # Apply dropout during training\n",
    "        if train:\n",
    "            attn_weights = nn.Dropout(rate=drop_rate, deterministic=not train)(attn_weights)\n",
    "\n",
    "        # Compute weighted sum\n",
    "        context_vec = jnp.matmul(attn_weights, values)  # [b, h, n, d]\n",
    "        context_vec = jnp.transpose(context_vec, (0, 2, 1, 3))  # [b, n, h, d]\n",
    "        context_vec = context_vec.reshape(b, num_tokens, emb_size)\n",
    "\n",
    "        # Final projection\n",
    "        context_vec = nn.Dense(emb_size, use_bias=False)(context_vec)\n",
    "        return context_vec"
   ],
   "id": "2fedb58f96697068",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T18:31:50.805991Z",
     "start_time": "2025-03-02T18:31:50.793609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeedForward(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(emb_size * 4)(x)\n",
    "        x = nn.gelu(x)\n",
    "        x = nn.Dense(emb_size)(x)\n",
    "        return x"
   ],
   "id": "aca6e1e9e5650cee",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T18:44:07.231137Z",
     "start_time": "2025-03-02T18:44:07.225403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, train=True):\n",
    "        shortcut = x\n",
    "        x = nn.LayerNorm()(x)\n",
    "        x = MultiHeadAttention()(x, train=train)\n",
    "        x = nn.Dropout(rate=drop_rate, deterministic=not train)(x)\n",
    "        x = x + shortcut\n",
    "        shortcut = x\n",
    "        x = nn.LayerNorm()(x)\n",
    "        x = FeedForward()(x)\n",
    "        x = nn.Dropout(rate=drop_rate, deterministic=not train)(x)\n",
    "        x = x + shortcut\n",
    "        return x"
   ],
   "id": "853a395fc37b99da",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T18:54:40.479671Z",
     "start_time": "2025-03-02T18:54:40.471320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BERTModel(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, in_idx, train=True):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = nn.Embed(tokenizer.vocab_size, emb_size)(in_idx)\n",
    "        pos_embeds = nn.Embed(tokenizer.vocab_size, emb_size)(jnp.arange(seq_len))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = nn.Dropout(rate=drop_rate, deterministic=not train)(x)\n",
    "        for _ in range(enc_layers):\n",
    "            x = TransformerBlock()(x, train=train)\n",
    "        return x\n",
    "\n"
   ],
   "id": "82d1c87f6220d66f",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T18:55:16.212041Z",
     "start_time": "2025-03-02T18:55:16.150661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emb_0 = test_encoded['input_ids'][0]\n",
    "emb_1 = test_encoded['input_ids'][1]\n",
    "\n",
    "baetch = jnp.stack([emb_0, emb_1])"
   ],
   "id": "77019653acc1312e",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T18:55:30.607058Z",
     "start_time": "2025-03-02T18:55:28.654385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = BERTModel()\n",
    "params = model.init(random.PRNGKey(0), baetch)"
   ],
   "id": "ff3847f3d53894f3",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T18:56:29.342134Z",
     "start_time": "2025-03-02T18:56:29.234960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a PRNG key for dropout\n",
    "dropout_key = random.PRNGKey(0)\n",
    "\n",
    "# Apply the model with the dropout key\n",
    "outputs = model.apply(params, baetch, rngs={'dropout': dropout_key})"
   ],
   "id": "8664834c459659a9",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T18:56:34.079504Z",
     "start_time": "2025-03-02T18:56:34.073475Z"
    }
   },
   "cell_type": "code",
   "source": "outputs",
   "id": "668811349cd6935f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[-0.8792379 ,  2.6149247 ,  2.4732218 , ..., -1.1531113 ,\n",
       "          1.3427374 ,  3.8533928 ],\n",
       "        [-1.8717792 ,  1.0434839 ,  4.0751777 , ..., -1.9849678 ,\n",
       "         -0.02247733,  2.038329  ],\n",
       "        [-2.6814907 ,  3.689282  ,  3.0881677 , ..., -3.0864406 ,\n",
       "          1.3580472 ,  2.094426  ],\n",
       "        ...,\n",
       "        [-1.043855  ,  3.3947158 ,  1.1680014 , ..., -1.5841985 ,\n",
       "         -0.06316358,  2.5258775 ],\n",
       "        [-2.7131894 ,  5.170878  ,  0.6641097 , ..., -2.290063  ,\n",
       "         -1.1589377 ,  2.0320249 ],\n",
       "        [-1.9094371 ,  1.2198724 ,  2.6021    , ..., -1.3415163 ,\n",
       "         -1.1853034 ,  1.2561945 ]],\n",
       "\n",
       "       [[-3.1883032 ,  5.320793  ,  3.510557  , ..., -1.8480575 ,\n",
       "          1.8133299 ,  2.7664046 ],\n",
       "        [-1.6124862 ,  5.208761  ,  4.3846183 , ..., -1.4063144 ,\n",
       "          1.6901441 ,  3.7757235 ],\n",
       "        [-2.323461  ,  2.7385266 ,  3.5919883 , ..., -1.0413522 ,\n",
       "          1.2736855 ,  2.2689352 ],\n",
       "        ...,\n",
       "        [-3.6155784 ,  3.7178936 ,  3.97956   , ..., -1.8154433 ,\n",
       "          2.6590424 ,  2.4221225 ],\n",
       "        [-2.5025158 ,  5.192652  ,  3.5094476 , ..., -1.1473054 ,\n",
       "          0.05388534,  3.3486547 ],\n",
       "        [-2.422709  ,  4.3410254 ,  2.0726058 , ..., -1.0552369 ,\n",
       "          0.7382744 ,  3.9334984 ]]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e94d6d6e6f427dea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
