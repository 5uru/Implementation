{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:51:32.567579Z",
     "start_time": "2025-03-06T08:51:32.560531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "from collections import Counter\n"
   ],
   "id": "93f5f7f0949aca1e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Make Tokenizer and Vocabulary Building",
   "id": "e6557d6342f032b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:35:51.014041Z",
     "start_time": "2025-03-06T08:35:49.346058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Shakespeare dataset\n",
    "!wget -O input.txt https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ],
   "id": "df7a94c96ae0f056",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-06 09:35:49--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1115394 (1.1M) [text/plain]\r\n",
      "Saving to: ‘input.txt’\r\n",
      "\r\n",
      "input.txt           100%[===================>]   1.06M  2.13MB/s    in 0.5s    \r\n",
      "\r\n",
      "2025-03-06 09:35:50 (2.13 MB/s) - ‘input.txt’ saved [1115394/1115394]\r\n",
      "\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:36:03.230932Z",
     "start_time": "2025-03-06T08:36:03.226373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('input.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "print(len(data))"
   ],
   "id": "69b613b7345837a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:36:41.098636Z",
     "start_time": "2025-03-06T08:36:41.082364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into lines\n",
    "lines = data.splitlines()\n",
    "\n",
    "# Remove empty lines\n",
    "no_sp_lines = []\n",
    "for elem in lines:\n",
    "    if elem != '':\n",
    "        no_sp_lines.append(elem)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Concatenate lines that end with ':'\n",
    "cat_lines = []\n",
    "i = 0\n",
    "\n",
    "while i < len(no_sp_lines):\n",
    "    if no_sp_lines[i].endswith(':'):\n",
    "        x = no_sp_lines[i] + ' ' + no_sp_lines[i + 1]\n",
    "        cat_lines.append(x)\n",
    "        i += 2\n",
    "    else:\n",
    "        cat_lines.append(no_sp_lines[i])\n",
    "        i += 1"
   ],
   "id": "3f6e9dbf39442be3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:36:57.536888Z",
     "start_time": "2025-03-06T08:36:57.531022Z"
    }
   },
   "cell_type": "code",
   "source": "cat_lines[:30]",
   "id": "f93985fcb62998ef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Citizen: Before we proceed any further, hear me speak.',\n",
       " 'All: Speak, speak.',\n",
       " 'First Citizen: You are all resolved rather to die than to famish?',\n",
       " 'All: Resolved. resolved.',\n",
       " 'First Citizen: First, you know Caius Marcius is chief enemy to the people.',\n",
       " \"All: We know't, we know't.\",\n",
       " \"First Citizen: Let us kill him, and we'll have corn at our own price.\",\n",
       " \"Is't a verdict?\",\n",
       " \"All: No more talking on't; let it be done: away, away!\",\n",
       " 'Second Citizen: One word, good citizens.',\n",
       " 'First Citizen: We are accounted poor citizens, the patricians good.',\n",
       " 'What authority surfeits on would relieve us: if they',\n",
       " 'would yield us but the superfluity, while it were',\n",
       " 'wholesome, we might guess they relieved us humanely;',\n",
       " 'but they think we are too dear: the leanness that',\n",
       " 'afflicts us, the object of our misery, is as an',\n",
       " 'inventory to particularise their abundance; our',\n",
       " 'sufferance is a gain to them Let us revenge this with',\n",
       " 'our pikes, ere we become rakes: for the gods know I',\n",
       " 'speak this in hunger for bread, not in thirst for revenge.',\n",
       " 'Second Citizen: Would you proceed especially against Caius Marcius?',\n",
       " \"All: Against him first: he's a very dog to the commonalty.\",\n",
       " 'Second Citizen: Consider you what services he has done for his country?',\n",
       " 'First Citizen: Very well; and could be content to give him good',\n",
       " 'report fort, but that he pays himself with being proud.',\n",
       " 'Second Citizen: Nay, but speak not maliciously.',\n",
       " 'First Citizen: I say unto you, what he hath done famously, he did',\n",
       " 'it to that end: though soft-conscienced men can be',\n",
       " 'content to say it was for his country he did it to',\n",
       " 'please his mother and to be partly proud; which he']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:37:01.148831Z",
     "start_time": "2025-03-06T08:37:01.145691Z"
    }
   },
   "cell_type": "code",
   "source": "len(cat_lines)",
   "id": "1414faa28b6badab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24618"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:43:30.069887Z",
     "start_time": "2025-03-06T08:43:30.055811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data in Train and Test\n",
    "train = cat_lines[:int(0.8*len(cat_lines))]\n",
    "test = cat_lines[int(0.8*len(cat_lines)):]"
   ],
   "id": "3b9d1111c3769f84",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:43:32.989150Z",
     "start_time": "2025-03-06T08:43:32.984874Z"
    }
   },
   "cell_type": "code",
   "source": "train[:10]",
   "id": "c6f13efdb21b73e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Citizen: Before we proceed any further, hear me speak.',\n",
       " 'All: Speak, speak.',\n",
       " 'First Citizen: You are all resolved rather to die than to famish?',\n",
       " 'All: Resolved. resolved.',\n",
       " 'First Citizen: First, you know Caius Marcius is chief enemy to the people.',\n",
       " \"All: We know't, we know't.\",\n",
       " \"First Citizen: Let us kill him, and we'll have corn at our own price.\",\n",
       " \"Is't a verdict?\",\n",
       " \"All: No more talking on't; let it be done: away, away!\",\n",
       " 'Second Citizen: One word, good citizens.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:43:37.120685Z",
     "start_time": "2025-03-06T08:43:37.117291Z"
    }
   },
   "cell_type": "code",
   "source": "test[:10]",
   "id": "4dcf5c30494d7b7f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What man thou art.',\n",
       " 'ANGELO: Who will believe thee, Isabel?',\n",
       " \"My unsoil'd name, the austereness of my life,\",\n",
       " \"My vouch against you, and my place i' the state,\",\n",
       " 'Will so your accusation overweigh,',\n",
       " 'That you shall stifle in your own report',\n",
       " 'And smell of calumny. I have begun,',\n",
       " 'And now I give my sensual race the rein: Fit thy consent to my sharp appetite;',\n",
       " 'Lay by all nicety and prolixious blushes,',\n",
       " 'That banish what they sue for; redeem thy brother']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:43:57.034381Z",
     "start_time": "2025-03-06T08:43:57.028061Z"
    }
   },
   "cell_type": "code",
   "source": "len(train), len(test)",
   "id": "7f26e7d50dcd7724",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19694, 4924)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:48:16.181156Z",
     "start_time": "2025-03-06T08:48:16.165328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def simple_tokenize(sentence):\n",
    "    for p in [\".\", \",\", \"?\", \"!\", \":\", \";\"]:\n",
    "        sentence = sentence.replace(p, \"\")\n",
    "    tokens = sentence.strip().split()\n",
    "    return tokens"
   ],
   "id": "2212bb5fa4235e99",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:48:26.430592Z",
     "start_time": "2025-03-06T08:48:26.352009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_tokens = [simple_tokenize(sentence) for sentence in train]\n",
    "test_tokens = [simple_tokenize(sentence) for sentence in test]"
   ],
   "id": "c0c5efbbc8e1197f",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:48:32.952787Z",
     "start_time": "2025-03-06T08:48:32.948822Z"
    }
   },
   "cell_type": "code",
   "source": "train_tokens[:10]",
   "id": "d8ccc4f6d0a96b40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['First',\n",
       "  'Citizen',\n",
       "  'Before',\n",
       "  'we',\n",
       "  'proceed',\n",
       "  'any',\n",
       "  'further',\n",
       "  'hear',\n",
       "  'me',\n",
       "  'speak'],\n",
       " ['All', 'Speak', 'speak'],\n",
       " ['First',\n",
       "  'Citizen',\n",
       "  'You',\n",
       "  'are',\n",
       "  'all',\n",
       "  'resolved',\n",
       "  'rather',\n",
       "  'to',\n",
       "  'die',\n",
       "  'than',\n",
       "  'to',\n",
       "  'famish'],\n",
       " ['All', 'Resolved', 'resolved'],\n",
       " ['First',\n",
       "  'Citizen',\n",
       "  'First',\n",
       "  'you',\n",
       "  'know',\n",
       "  'Caius',\n",
       "  'Marcius',\n",
       "  'is',\n",
       "  'chief',\n",
       "  'enemy',\n",
       "  'to',\n",
       "  'the',\n",
       "  'people'],\n",
       " ['All', 'We', \"know't\", 'we', \"know't\"],\n",
       " ['First',\n",
       "  'Citizen',\n",
       "  'Let',\n",
       "  'us',\n",
       "  'kill',\n",
       "  'him',\n",
       "  'and',\n",
       "  \"we'll\",\n",
       "  'have',\n",
       "  'corn',\n",
       "  'at',\n",
       "  'our',\n",
       "  'own',\n",
       "  'price'],\n",
       " [\"Is't\", 'a', 'verdict'],\n",
       " ['All',\n",
       "  'No',\n",
       "  'more',\n",
       "  'talking',\n",
       "  \"on't\",\n",
       "  'let',\n",
       "  'it',\n",
       "  'be',\n",
       "  'done',\n",
       "  'away',\n",
       "  'away'],\n",
       " ['Second', 'Citizen', 'One', 'word', 'good', 'citizens']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:53:05.609920Z",
     "start_time": "2025-03-06T08:53:05.597263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# All-tokens test and train\n",
    "all_tokens =[]\n",
    "for elem in train_tokens:\n",
    "    all_tokens.extend(elem)\n",
    "for elem in test_tokens:\n",
    "    all_tokens.extend(elem)"
   ],
   "id": "abceea81f8985cf9",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:53:23.717602Z",
     "start_time": "2025-03-06T08:53:23.691816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "counts = Counter(all_tokens)\n",
    "vocab = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"] + sorted(counts)\n",
    "word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocab size: {vocab_size}\")"
   ],
   "id": "a26da30d1404b69e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 15539\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:55:52.936225Z",
     "start_time": "2025-03-06T08:55:52.931500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encoding Sentences\n",
    "def encode(tokens, word2idx, max_len=12):\n",
    "    tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "    token_ids = []\n",
    "    for t in tokens:\n",
    "        token_ids.append(word2idx.get(t, word2idx[\"[UNK]\"]))\n",
    "    if len(token_ids) < max_len:\n",
    "        token_ids += [word2idx[\"[PAD]\"]] * (max_len - len(token_ids))\n",
    "    else:\n",
    "        token_ids = token_ids[:max_len]\n",
    "    return token_ids"
   ],
   "id": "2fd8e4a79aa8f4f6",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T08:56:45.887151Z",
     "start_time": "2025-03-06T08:56:45.076072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_enc = [encode(tokens, word2idx) for tokens in train_tokens]\n",
    "test_enc = [encode(tokens, word2idx) for tokens in test_tokens]\n",
    "\n",
    "train_enc = jnp.array(train_enc)\n",
    "test_enc = jnp.array(test_enc)\n",
    "print(f\"Encoded dataset shape: {train_enc.shape}\")"
   ],
   "id": "ef1a06ccc41af0b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded dataset shape: (19694, 12)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Masking",
   "id": "86a6cd498cd07cbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:21:00.081587Z",
     "start_time": "2025-03-06T18:21:00.063477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mask(batch, key, mask_prob=0.15):\n",
    "    \"\"\"JAX-vectorized masking function compatible with JIT\"\"\"\n",
    "    # Split the key for masking and model operations\n",
    "    mask_key, model_key = jax.random.split(key)\n",
    "\n",
    "    # Generate random values for masking decisions\n",
    "    mask_matrix = jax.random.uniform(mask_key, shape=batch.shape)\n",
    "\n",
    "    # Set up special token handling\n",
    "    special_ids = jnp.array([word2idx[\"[PAD]\"], word2idx[\"[CLS]\"],\n",
    "                             word2idx[\"[SEP]\"], word2idx[\"[MASK]\"]])\n",
    "\n",
    "    # Check which tokens are special (vectorized)\n",
    "    is_special = jnp.zeros_like(batch, dtype=bool)\n",
    "    for special_id in special_ids:\n",
    "        is_special = is_special | (batch == special_id)\n",
    "\n",
    "    # Determine which tokens should be masked\n",
    "    should_mask = (mask_matrix < mask_prob) & (~is_special)\n",
    "\n",
    "    # Create masked input and labels\n",
    "    input_ids = jnp.where(should_mask, word2idx[\"[MASK]\"], batch)\n",
    "    labels = jnp.where(should_mask, batch, -100)\n",
    "\n",
    "    return input_ids, labels, model_key"
   ],
   "id": "ad17b6a32a586bec",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Transformer Architecture",
   "id": "a9a2ac30304b583c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T09:20:51.941795Z",
     "start_time": "2025-03-06T09:20:51.930785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    embed_dim: int\n",
    "    num_heads: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        assert self.embed_dim % self.num_heads == 0\n",
    "        head_dim = self.embed_dim // self.num_heads\n",
    "\n",
    "        B, S, E = x.shape\n",
    "        query = nn.Dense(self.embed_dim)(x)\n",
    "        key = nn.Dense(self.embed_dim)(x)\n",
    "        value = nn.Dense(self.embed_dim)(x)\n",
    "\n",
    "        key = key.reshape((B, S, self.num_heads, head_dim)).transpose((0, 2, 1, 3))\n",
    "        query = query.reshape((B, S, self.num_heads, head_dim)).transpose((0, 2, 1, 3))\n",
    "        value = value.reshape((B, S, self.num_heads, head_dim)).transpose((0, 2, 1, 3))\n",
    "\n",
    "        score = jnp.matmul(query, key.transpose((0, 1, 3, 2))) / jnp.sqrt(head_dim)\n",
    "        attn_weights = nn.softmax(score, axis=-1)\n",
    "        context = jnp.matmul(attn_weights, value)\n",
    "        context = context.transpose((0, 2, 1, 3)).reshape((B, S, self.embed_dim))\n",
    "        out = nn.Dense(self.embed_dim)(context)\n",
    "        return out"
   ],
   "id": "2b179deee0e0cbaa",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T09:43:45.952595Z",
     "start_time": "2025-03-06T09:43:45.940747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerEncoderBlock(nn.Module):\n",
    "    embed_dim: int\n",
    "    num_heads: int\n",
    "    ff_dim: int\n",
    "    dropout_rate: float\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, deterministic=False):\n",
    "        attn = MultiHeadSelfAttention(self.embed_dim, self.num_heads)(x)\n",
    "        x = nn.LayerNorm()(x + nn.Dropout(rate=self.dropout_rate, deterministic=deterministic)(attn))\n",
    "        ff = nn.Dense(self.ff_dim)(x)\n",
    "        ff = nn.relu(ff)\n",
    "        ff = nn.Dense(self.embed_dim)(ff)\n",
    "        x = nn.LayerNorm()(x + nn.Dropout(rate=self.dropout_rate, deterministic=deterministic)(ff))\n",
    "        return x\n"
   ],
   "id": "52e65373bb1d3fcd",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T09:52:48.594476Z",
     "start_time": "2025-03-06T09:52:48.587582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    embed_dim: int\n",
    "    max_len: int = 1000\n",
    "\n",
    "    def setup(self):\n",
    "        # Create positional encoding once during initialization\n",
    "        position = jnp.expand_dims(jnp.arange(0, self.max_len), 1)\n",
    "        div_term = jnp.exp(jnp.arange(0, self.embed_dim, 2) * -(jnp.log(10000.0) / self.embed_dim))\n",
    "\n",
    "        pe = jnp.zeros((self.max_len, self.embed_dim))\n",
    "        pe = pe.at[:, 0::2].set(jnp.sin(position * div_term))\n",
    "        pe = pe.at[:, 1::2].set(jnp.cos(position * div_term))\n",
    "        self.pe = pe\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # x shape: (batch_size, seq_len, embed_dim)\n",
    "        return x + self.pe[:x.shape[1], :]"
   ],
   "id": "58d9267ad505e24e",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:34:50.942894Z",
     "start_time": "2025-03-06T10:34:50.931543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Bert(nn.Module):\n",
    "    vocab_size: int\n",
    "    embed_dim: int =64\n",
    "    max_len: int = 12\n",
    "    num_heads: int = 2\n",
    "    ff_dim: int = 128\n",
    "    num_layers: int = 2\n",
    "    dropout_rate: float = 0.1\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, deterministic=False):\n",
    "        x = nn.Embed(self.vocab_size, self.embed_dim)(x)\n",
    "        x = PositionalEncoding(self.embed_dim, self.max_len)(x)\n",
    "        x = nn.Dropout(rate=self.dropout_rate, deterministic=deterministic)(x)\n",
    "\n",
    "        for _ in range(self.num_layers):\n",
    "            x = TransformerEncoderBlock(self.embed_dim, self.num_heads, self.ff_dim, self.dropout_rate)(x, deterministic=deterministic)\n",
    "        x = nn.Dense(self.vocab_size)(x)\n",
    "        return x"
   ],
   "id": "3c6feaaa10f48665",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train the Model",
   "id": "437704a546fbaeef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:38:01.786860Z",
     "start_time": "2025-03-06T10:38:01.708880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "model = Bert(vocab_size=vocab_size)\n",
    "params = model.init(jax.random.PRNGKey(0), jnp.ones((1, 12), jnp.int32), deterministic=True)\n"
   ],
   "id": "96333a275293373b",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:43:53.219947Z",
     "start_time": "2025-03-06T10:43:53.216952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the optimizer\n",
    "optimizer = optax.adam(learning_rate=1e-3)"
   ],
   "id": "1a9d54084608c6c2",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T10:43:54.028827Z",
     "start_time": "2025-03-06T10:43:54.004288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train State\n",
    "model_state = train_state.TrainState.create(apply_fn=model.apply, params=params, tx=optimizer)"
   ],
   "id": "1be01830dd88ec8f",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:33:57.806100Z",
     "start_time": "2025-03-06T18:33:57.793683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_loss(params, batch, key, apply_fn):\n",
    "    \"\"\"Calculate the masked language modeling loss.\"\"\"\n",
    "    input_ids, labels, dropout_key = mask(batch, key)\n",
    "\n",
    "    logits = apply_fn(\n",
    "            params,\n",
    "            input_ids,\n",
    "            deterministic=False,\n",
    "            rngs={'dropout': dropout_key}\n",
    "    )\n",
    "\n",
    "    # Create a mask to zero out the loss for -100 labels\n",
    "    loss_mask = jnp.where(labels != -100, 1.0, 0.0)\n",
    "\n",
    "    # Replace -100 with 0 to avoid numerical issues\n",
    "    valid_labels = jnp.maximum(labels, 0)\n",
    "\n",
    "    # Calculate loss for all positions\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "            logits=logits.reshape(-1, logits.shape[-1]),\n",
    "            labels=valid_labels.reshape(-1)\n",
    "    )\n",
    "\n",
    "    # Apply mask and calculate mean over only the valid positions\n",
    "    loss = jnp.sum(loss * loss_mask.reshape(-1)) / (jnp.sum(loss_mask) + 1e-8)\n",
    "\n",
    "    return loss"
   ],
   "id": "12e68f8b905bb52f",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:34:00.266596Z",
     "start_time": "2025-03-06T18:34:00.259640Z"
    }
   },
   "cell_type": "code",
   "source": "grad_fn = jax.value_and_grad(calculate_loss, argnums=0)",
   "id": "b196690f82763009",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:34:00.695128Z",
     "start_time": "2025-03-06T18:34:00.690278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "@jax.jit\n",
    "def train_step(state, batch, key):\n",
    "    loss, grads = grad_fn(state.params, batch, key, state.apply_fn)\n",
    "    new_state = state.apply_gradients(grads=grads)\n",
    "    return new_state, loss"
   ],
   "id": "4597d385180fcd27",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T18:34:01.331753Z",
     "start_time": "2025-03-06T18:34:01.329600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "batch_size = 2\n",
    "dataset_size = train_enc.shape[0]"
   ],
   "id": "c71d54b91986f6c8",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-06T18:34:03.104188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "    key = jax.random.PRNGKey(epoch)  # Create a key based on epoch\n",
    "    indices = jax.random.permutation(key, dataset_size)\n",
    "\n",
    "    for i in range(0, dataset_size, batch_size):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        batch_indices = indices[i:i+batch_size]\n",
    "        if len(batch_indices) < batch_size:\n",
    "            continue  # Skip incomplete batches\n",
    "\n",
    "        batch = train_enc[batch_indices]\n",
    "        model_state, loss = train_step(model_state, batch, subkey)\n",
    "        total_loss += loss\n",
    "        batch_count += 1\n",
    "\n",
    "    avg_loss = total_loss / batch_count if batch_count > 0 else 0\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")"
   ],
   "id": "52efb84e1eee4524",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2958a8beeeb7b98"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
