{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-03T19:15:56.460974Z",
     "start_time": "2025-03-03T19:15:56.449936Z"
    }
   },
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.nn.initializers import normal as normal_init\n",
    "from flax.training.train_state import TrainState\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "from transformers import BertTokenizer\n",
    "from jax import random"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Hyperparameters",
   "id": "7d46794c773ba5c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:20.837583Z",
     "start_time": "2025-03-03T19:09:20.835422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "enc_layers = 6\n",
    "head_count = 12\n",
    "emb_size = 384 # from 12\n",
    "seq_len = 36\n",
    "drop_rate = 0.1"
   ],
   "id": "a7c099c709e378d0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get the data",
   "id": "1507281f62267a2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:39.865509Z",
     "start_time": "2025-03-03T19:09:20.992166Z"
    }
   },
   "cell_type": "code",
   "source": "!wget -O input.txt https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt",
   "id": "fdca2c506503d867",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-03 20:09:21--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1115394 (1.1M) [text/plain]\r\n",
      "Saving to: ‘input.txt’\r\n",
      "\r\n",
      "input.txt           100%[===================>]   1.06M  79.5KB/s    in 18s     \r\n",
      "\r\n",
      "2025-03-03 20:09:39 (61.8 KB/s) - ‘input.txt’ saved [1115394/1115394]\r\n",
      "\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:39.887904Z",
     "start_time": "2025-03-03T19:09:39.881124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "with open('input.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "print(len(data))"
   ],
   "id": "37191de45f04f822",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:39.913642Z",
     "start_time": "2025-03-03T19:09:39.909888Z"
    }
   },
   "cell_type": "code",
   "source": "print(data[:100])",
   "id": "8c50a1abf432856b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:39.957906Z",
     "start_time": "2025-03-03T19:09:39.944101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into lines\n",
    "lines = data.splitlines()\n",
    "lines[:10]"
   ],
   "id": "f769b346a20b6053",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Citizen:',\n",
       " 'Before we proceed any further, hear me speak.',\n",
       " '',\n",
       " 'All:',\n",
       " 'Speak, speak.',\n",
       " '',\n",
       " 'First Citizen:',\n",
       " 'You are all resolved rather to die than to famish?',\n",
       " '',\n",
       " 'All:']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:39.978809Z",
     "start_time": "2025-03-03T19:09:39.974120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove empty lines\n",
    "no_sp_lines = []\n",
    "for elem in lines:\n",
    "    if elem != '':\n",
    "        no_sp_lines.append(elem)\n",
    "    else:\n",
    "        continue"
   ],
   "id": "876eb9ed963a8293",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:40.003813Z",
     "start_time": "2025-03-03T19:09:39.999272Z"
    }
   },
   "cell_type": "code",
   "source": "no_sp_lines[:5]\n",
   "id": "aba71947af2a41ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Citizen:',\n",
       " 'Before we proceed any further, hear me speak.',\n",
       " 'All:',\n",
       " 'Speak, speak.',\n",
       " 'First Citizen:']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:40.031409Z",
     "start_time": "2025-03-03T19:09:40.024164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Concatenate lines that end with ':'\n",
    "cat_lines = []\n",
    "i = 0\n",
    "\n",
    "while i < len(no_sp_lines):\n",
    "    if no_sp_lines[i].endswith(':'):\n",
    "        x = no_sp_lines[i] + ' ' + no_sp_lines[i + 1]\n",
    "        cat_lines.append(x)\n",
    "        i += 2\n",
    "    else:\n",
    "        cat_lines.append(no_sp_lines[i])\n",
    "        i += 1"
   ],
   "id": "9ae2ac5d1f457029",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:40.043866Z",
     "start_time": "2025-03-03T19:09:40.039177Z"
    }
   },
   "cell_type": "code",
   "source": "cat_lines[:30]",
   "id": "908f5a01719ec975",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Citizen: Before we proceed any further, hear me speak.',\n",
       " 'All: Speak, speak.',\n",
       " 'First Citizen: You are all resolved rather to die than to famish?',\n",
       " 'All: Resolved. resolved.',\n",
       " 'First Citizen: First, you know Caius Marcius is chief enemy to the people.',\n",
       " \"All: We know't, we know't.\",\n",
       " \"First Citizen: Let us kill him, and we'll have corn at our own price.\",\n",
       " \"Is't a verdict?\",\n",
       " \"All: No more talking on't; let it be done: away, away!\",\n",
       " 'Second Citizen: One word, good citizens.',\n",
       " 'First Citizen: We are accounted poor citizens, the patricians good.',\n",
       " 'What authority surfeits on would relieve us: if they',\n",
       " 'would yield us but the superfluity, while it were',\n",
       " 'wholesome, we might guess they relieved us humanely;',\n",
       " 'but they think we are too dear: the leanness that',\n",
       " 'afflicts us, the object of our misery, is as an',\n",
       " 'inventory to particularise their abundance; our',\n",
       " 'sufferance is a gain to them Let us revenge this with',\n",
       " 'our pikes, ere we become rakes: for the gods know I',\n",
       " 'speak this in hunger for bread, not in thirst for revenge.',\n",
       " 'Second Citizen: Would you proceed especially against Caius Marcius?',\n",
       " \"All: Against him first: he's a very dog to the commonalty.\",\n",
       " 'Second Citizen: Consider you what services he has done for his country?',\n",
       " 'First Citizen: Very well; and could be content to give him good',\n",
       " 'report fort, but that he pays himself with being proud.',\n",
       " 'Second Citizen: Nay, but speak not maliciously.',\n",
       " 'First Citizen: I say unto you, what he hath done famously, he did',\n",
       " 'it to that end: though soft-conscienced men can be',\n",
       " 'content to say it was for his country he did it to',\n",
       " 'please his mother and to be partly proud; which he']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tokenizers",
   "id": "9630c5cccded2153"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:43.553224Z",
     "start_time": "2025-03-03T19:09:40.065710Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')",
   "id": "41dffdfd03adf9cc",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:43.572437Z",
     "start_time": "2025-03-03T19:09:43.569494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Special tokens\n",
    "print(\"Special Tokens:\")\n",
    "print(\"CLS:\", tokenizer.cls_token)\n",
    "print(\"SEP:\", tokenizer.sep_token)\n",
    "print(\"PAD:\", tokenizer.pad_token)\n",
    "print(\"MASK:\", tokenizer.mask_token)\n",
    "print(\"UNK:\", tokenizer.unk_token)"
   ],
   "id": "2d2ad85bafdbe2af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special Tokens:\n",
      "CLS: [CLS]\n",
      "SEP: [SEP]\n",
      "PAD: [PAD]\n",
      "MASK: [MASK]\n",
      "UNK: [UNK]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:48.642693Z",
     "start_time": "2025-03-03T19:09:43.598526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence = \"To be, or not to be.\"\n",
    "encoded = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "\n",
    "print(\"\\nEncoded with special tokens:\", encoded)\n",
    "print(\"Decoded back:\", tokenizer.decode(encoded))"
   ],
   "id": "19480ade3ba0e662",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded with special tokens: [101, 2000, 2022, 1010, 2030, 2025, 2000, 2022, 1012, 102]\n",
      "Decoded back: [CLS] to be, or not to be. [SEP]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:50:54.474969Z",
     "start_time": "2025-03-03T19:50:54.472042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def masker(encoded_text, key):\n",
    "    masking_prob = 0.15\n",
    "    masked_input_ids = encoded_text.clone()  # Make sure we don't modify the original tensor\n",
    "    labels = encoded_text.clone()  # Same for labels\n",
    "\n",
    "    for i in range(len(encoded_text)):\n",
    "        key, subkey1, subkey2 = random.split(key, 3)\n",
    "        if jax.random.uniform(key, minval=0, maxval=1) < masking_prob and masked_input_ids[i] not in tokenizer.all_special_ids:\n",
    "            # Replace with [MASK] 80% of the time\n",
    "            if jax.random.uniform(subkey1, minval=0, maxval=1) < 0.8:\n",
    "                masked_input_ids = masked_input_ids.at[i].set(tokenizer.mask_token_id)\n",
    "            # Replace with a random token 10% of the time\n",
    "            elif jax.random.uniform(subkey2, minval=0, maxval=1) < 0.9:\n",
    "                masked_input_ids = masked_input_ids.at[i].set(random.randint(subkey2,shape=(1,),minval=0, maxval=tokenizer.vocab_size - 1))\n",
    "            # Keep the original word 10% of the time\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    # Set the labels to -100 for the positions that were masked\n",
    "    #labels[masked_input_ids == tokenizer.mask_token_id] = -100\n",
    "    return masked_input_ids, labels#"
   ],
   "id": "988c8de6d5bd34f2",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:54.660885Z",
     "start_time": "2025-03-03T19:09:48.661758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_encoded = tokenizer(\n",
    "        cat_lines,\n",
    "        padding='max_length',\n",
    "        #truncation=True,\n",
    "        max_length=36,\n",
    "        return_tensors=\"jax\"\n",
    ")\n"
   ],
   "id": "6d1545930faa89fd",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:54.767730Z",
     "start_time": "2025-03-03T19:09:54.669197Z"
    }
   },
   "cell_type": "code",
   "source": "test_encoded['input_ids'][0]",
   "id": "89e0856917fa37e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([  101,  2034,  6926,  1024,  2077,  2057, 10838,  2151,  2582,\n",
       "        1010,  2963,  2033,  3713,  1012,   102,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0],      dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:54.775632Z",
     "start_time": "2025-03-03T19:09:54.772718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BidirectionalSelfAttention(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        query = nn.Dense(emb_size, use_bias=False)(x)\n",
    "        key = nn.Dense(emb_size, use_bias=False)(x)\n",
    "        value = nn.Dense(emb_size, use_bias=False)(x)\n",
    "\n",
    "        attention_scores = jnp.matmul(query, key.T)\n",
    "        attention_weights = jax.nn.softmax(attention_scores / key.shape[-1]**0.5, axis=-1)\n",
    "        context_vector = jnp.matmul(attention_weights, value)\n",
    "        return context_vector\n"
   ],
   "id": "9c20594a90a02a57",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:54.789440Z",
     "start_time": "2025-03-03T19:09:54.785862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    head_dim: int = emb_size // head_count\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, train=True):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = nn.Dense(emb_size, use_bias=False)(x)\n",
    "        queries = nn.Dense(emb_size, use_bias=False)(x)\n",
    "        values = nn.Dense(emb_size, use_bias=False)(x)\n",
    "\n",
    "        # Reshape to separate the head dimension\n",
    "        keys = keys.reshape(b, num_tokens, head_count, self.head_dim)\n",
    "        values = values.reshape(b, num_tokens, head_count, self.head_dim)\n",
    "        queries = queries.reshape(b, num_tokens, head_count, self.head_dim)\n",
    "\n",
    "        # Transpose for attention computation\n",
    "        keys = jnp.transpose(keys, (0, 2, 1, 3))      # [b, h, n, d]\n",
    "        values = jnp.transpose(values, (0, 2, 1, 3))  # [b, h, n, d]\n",
    "        queries = jnp.transpose(queries, (0, 2, 1, 3)) # [b, h, n, d]\n",
    "\n",
    "        # Compute attention scores\n",
    "        attn_scores = jnp.matmul(queries, jnp.transpose(keys, (0, 1, 3, 2)))\n",
    "        attn_weights = jax.nn.softmax(attn_scores / jnp.sqrt(self.head_dim), axis=-1)\n",
    "\n",
    "        # Apply dropout during training\n",
    "        if train:\n",
    "            attn_weights = nn.Dropout(rate=drop_rate, deterministic=not train)(attn_weights)\n",
    "\n",
    "        # Compute weighted sum\n",
    "        context_vec = jnp.matmul(attn_weights, values)  # [b, h, n, d]\n",
    "        context_vec = jnp.transpose(context_vec, (0, 2, 1, 3))  # [b, n, h, d]\n",
    "        context_vec = context_vec.reshape(b, num_tokens, emb_size)\n",
    "\n",
    "        # Final projection\n",
    "        context_vec = nn.Dense(emb_size, use_bias=False)(context_vec)\n",
    "        return context_vec"
   ],
   "id": "2fedb58f96697068",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:54.799614Z",
     "start_time": "2025-03-03T19:09:54.797011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeedForward(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(emb_size * 4)(x)\n",
    "        x = nn.gelu(x)\n",
    "        x = nn.Dense(emb_size)(x)\n",
    "        return x"
   ],
   "id": "aca6e1e9e5650cee",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:54.814978Z",
     "start_time": "2025-03-03T19:09:54.811635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, train=True):\n",
    "        shortcut = x\n",
    "        x = nn.LayerNorm()(x)\n",
    "        x = MultiHeadAttention()(x, train=train)\n",
    "        x = nn.Dropout(rate=drop_rate, deterministic=not train)(x)\n",
    "        x = x + shortcut\n",
    "        shortcut = x\n",
    "        x = nn.LayerNorm()(x)\n",
    "        x = FeedForward()(x)\n",
    "        x = nn.Dropout(rate=drop_rate, deterministic=not train)(x)\n",
    "        x = x + shortcut\n",
    "        return x"
   ],
   "id": "853a395fc37b99da",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T19:09:54.820767Z",
     "start_time": "2025-03-03T19:09:54.817925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BERTModel(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, in_idx, train=True):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = nn.Embed(tokenizer.vocab_size, emb_size)(in_idx)\n",
    "        pos_embeds = nn.Embed(tokenizer.vocab_size, emb_size)(jnp.arange(seq_len))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = nn.Dropout(rate=drop_rate, deterministic=not train)(x)\n",
    "        for _ in range(enc_layers):\n",
    "            x = TransformerBlock()(x, train=train)\n",
    "        return x\n",
    "\n"
   ],
   "id": "82d1c87f6220d66f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:22:32.480834Z",
     "start_time": "2025-03-03T20:22:32.468134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_sample(key):\n",
    "    key1, key2 = random.split(key)\n",
    "    index1 = random.randint(key1,shape=(1,), minval=0, maxval=len(test_encoded['input_ids']) - 1)\n",
    "    random_line1 = test_encoded['input_ids'][index1]\n",
    "    if jax.random.uniform(key2, minval=0, maxval=1) < 0.5 and index1 < len(cat_lines)-1:\n",
    "        index2 = index1 + 1\n",
    "        random_line2 = test_encoded['input_ids'][index2]\n",
    "    else:\n",
    "        index2 = random.randint(key2,shape=(1,), minval=0, maxval=len(test_encoded['input_ids']) - 1)\n",
    "        random_line2 = test_encoded['input_ids'][index2]\n",
    "    return random_line1, random_line2"
   ],
   "id": "7111f04f77506c83",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:22:35.194947Z",
     "start_time": "2025-03-03T20:22:35.184434Z"
    }
   },
   "cell_type": "code",
   "source": "get_sample(random.PRNGKey(0))\n",
   "id": "3a4af8f3693f227",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[  101,  2005,  2029,  2115,  6225,  1998,  2115,  4752,  2003,\n",
       "         19175,  1005,  1040,  1025,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0]],      dtype=int32),\n",
       " Array([[  101,  1996,  4656,  9527,  1997, 21136,  1998,  1996,  2693,\n",
       "          3085,  2015,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0]],      dtype=int32))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:33:36.804612Z",
     "start_time": "2025-03-03T20:33:36.787139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def concatenate_and_adjust(tensor1, tensor2, target_size=36):\n",
    "    # Step 1: Strip zeros from the first tensor\n",
    "    tensor1_nonzero = tensor1[tensor1 != 0]\n",
    "\n",
    "    # Step 2: Concatenate the two tensors (taking the second token onward from tensor2)\n",
    "    if tensor2.ndim > 1:\n",
    "        concatenated = jnp.concatenate((tensor1_nonzero, tensor2[0, 1:]))\n",
    "    else:\n",
    "        concatenated = jnp.concatenate((tensor1_nonzero, tensor2[1:]))\n",
    "\n",
    "    # Step 3: Trim or pad with zeros to match the target size\n",
    "    if len(concatenated) > target_size:\n",
    "        concatenated = concatenated[:target_size]  # Trim to target size\n",
    "    elif len(concatenated) < target_size:\n",
    "        padding = jnp.zeros(target_size - len(concatenated), dtype=concatenated.dtype)\n",
    "        concatenated = jnp.concatenate((concatenated, padding))  # Pad with zeros\n",
    "\n",
    "    return concatenated"
   ],
   "id": "13ea94623e1f00c1",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:33:37.689746Z",
     "start_time": "2025-03-03T20:33:37.642207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a, b = get_sample(random.PRNGKey(0))\n",
    "c = concatenate_and_adjust(a, b)\n",
    "print(c)\n",
    "print(masker(c, random.PRNGKey(2)))"
   ],
   "id": "80d113ab1b37334c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101  2005  2029  2115  6225  1998  2115  4752  2003 19175  1005  1040\n",
      "  1025   102  1996  4656  9527  1997 21136  1998  1996  2693  3085  2015\n",
      "   102     0     0     0     0     0     0     0     0     0     0     0]\n",
      "(Array([  101,  2005,  2029,  2115,   103,  1998,  2115,  4752,  2003,\n",
      "         103,  1005,  1040,  1025,   102,  1996,  4656,  9527,  1997,\n",
      "       21136,  1998,  1996,  2693,  3085,   103,   102,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0],      dtype=int32), Array([  101,  2005,  2029,  2115,  6225,  1998,  2115,  4752,  2003,\n",
      "       19175,  1005,  1040,  1025,   102,  1996,  4656,  9527,  1997,\n",
      "       21136,  1998,  1996,  2693,  3085,  2015,   102,     0,     0,\n",
      "           0,     0,     0,     0,     0,     0,     0,     0,     0],      dtype=int32))\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:33:46.342099Z",
     "start_time": "2025-03-03T20:33:46.328181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emb_0 = test_encoded['input_ids'][0]\n",
    "emb_1 = test_encoded['input_ids'][1]\n",
    "\n",
    "baetch = masker(c, random.PRNGKey(2))[0]"
   ],
   "id": "77019653acc1312e",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:33:51.489206Z",
     "start_time": "2025-03-03T20:33:51.373348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = BERTModel()\n",
    "params = model.init(random.PRNGKey(0), baetch)"
   ],
   "id": "ff3847f3d53894f3",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[108], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m BERTModel()\n\u001B[0;32m----> 2\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPRNGKey\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbaetch\u001B[49m\u001B[43m)\u001B[49m\n",
      "    \u001B[0;31m[... skipping hidden 9 frame]\u001B[0m\n",
      "Cell \u001B[0;32mIn[21], line 4\u001B[0m, in \u001B[0;36mBERTModel.__call__\u001B[0;34m(self, in_idx, train)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;129m@nn\u001B[39m\u001B[38;5;241m.\u001B[39mcompact\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, in_idx, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m----> 4\u001B[0m     batch_size, seq_len \u001B[38;5;241m=\u001B[39m in_idx\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m      5\u001B[0m     tok_embeds \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mEmbed(tokenizer\u001B[38;5;241m.\u001B[39mvocab_size, emb_size)(in_idx)\n\u001B[1;32m      6\u001B[0m     pos_embeds \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mEmbed(tokenizer\u001B[38;5;241m.\u001B[39mvocab_size, emb_size)(jnp\u001B[38;5;241m.\u001B[39marange(seq_len))\n",
      "\u001B[0;31mValueError\u001B[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:33:39.835286Z",
     "start_time": "2025-03-03T20:33:39.808906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a PRNG key for dropout\n",
    "dropout_key = random.PRNGKey(0)\n",
    "\n",
    "# Apply the model with the dropout key\n",
    "outputs = model.apply(params, baetch, rngs={'dropout': dropout_key})"
   ],
   "id": "8664834c459659a9",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[104], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m dropout_key \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39mPRNGKey(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Apply the model with the dropout key\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbaetch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrngs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdropout\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout_key\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "    \u001B[0;31m[... skipping hidden 6 frame]\u001B[0m\n",
      "Cell \u001B[0;32mIn[21], line 4\u001B[0m, in \u001B[0;36mBERTModel.__call__\u001B[0;34m(self, in_idx, train)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;129m@nn\u001B[39m\u001B[38;5;241m.\u001B[39mcompact\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, in_idx, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m----> 4\u001B[0m     batch_size, seq_len \u001B[38;5;241m=\u001B[39m in_idx\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m      5\u001B[0m     tok_embeds \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mEmbed(tokenizer\u001B[38;5;241m.\u001B[39mvocab_size, emb_size)(in_idx)\n\u001B[1;32m      6\u001B[0m     pos_embeds \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mEmbed(tokenizer\u001B[38;5;241m.\u001B[39mvocab_size, emb_size)(jnp\u001B[38;5;241m.\u001B[39marange(seq_len))\n",
      "\u001B[0;31mValueError\u001B[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:33:40.177007Z",
     "start_time": "2025-03-03T20:33:40.167349Z"
    }
   },
   "cell_type": "code",
   "source": "outputs",
   "id": "668811349cd6935f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[-0.8792379 ,  2.6149247 ,  2.4732218 , ..., -1.1531113 ,\n",
       "          1.3427374 ,  3.8533928 ],\n",
       "        [-1.8717792 ,  1.0434839 ,  4.0751777 , ..., -1.9849678 ,\n",
       "         -0.02247733,  2.038329  ],\n",
       "        [-2.6814907 ,  3.689282  ,  3.0881677 , ..., -3.0864406 ,\n",
       "          1.3580472 ,  2.094426  ],\n",
       "        ...,\n",
       "        [-1.043855  ,  3.3947158 ,  1.1680014 , ..., -1.5841985 ,\n",
       "         -0.06316358,  2.5258775 ],\n",
       "        [-2.7131894 ,  5.170878  ,  0.6641097 , ..., -2.290063  ,\n",
       "         -1.1589377 ,  2.0320249 ],\n",
       "        [-1.9094371 ,  1.2198724 ,  2.6021    , ..., -1.3415163 ,\n",
       "         -1.1853034 ,  1.2561945 ]],\n",
       "\n",
       "       [[-3.1883032 ,  5.320793  ,  3.510557  , ..., -1.8480575 ,\n",
       "          1.8133299 ,  2.7664046 ],\n",
       "        [-1.6124862 ,  5.208761  ,  4.3846183 , ..., -1.4063144 ,\n",
       "          1.6901441 ,  3.7757235 ],\n",
       "        [-2.323461  ,  2.7385266 ,  3.5919883 , ..., -1.0413522 ,\n",
       "          1.2736855 ,  2.2689352 ],\n",
       "        ...,\n",
       "        [-3.6155784 ,  3.7178936 ,  3.97956   , ..., -1.8154433 ,\n",
       "          2.6590424 ,  2.4221225 ],\n",
       "        [-2.5025158 ,  5.192652  ,  3.5094476 , ..., -1.1473054 ,\n",
       "          0.05388534,  3.3486547 ],\n",
       "        [-2.422709  ,  4.3410254 ,  2.0726058 , ..., -1.0552369 ,\n",
       "          0.7382744 ,  3.9334984 ]]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:33:40.201032Z",
     "start_time": "2025-03-03T20:33:40.196866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_params(params):\n",
    "    return sum(x.size for x in jax.tree_util.tree_leaves(params))\n",
    "\n",
    "print(count_params(params)/1e6, 'M parameters')"
   ],
   "id": "28fba3d622c4c9ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.078464 M parameters\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Optimizer",
   "id": "c1bdfa08a9393e63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:07:16.982578Z",
     "start_time": "2025-03-03T20:07:16.890282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = optax.adam(3e-4)\n",
    "opt_state = optimizer.init(params)"
   ],
   "id": "eed26a9af44eada9",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:07:18.936229Z",
     "start_time": "2025-03-03T20:07:18.861073Z"
    }
   },
   "cell_type": "code",
   "source": "model_state = TrainState.create(apply_fn=model.apply, params=params, tx=optimizer,)",
   "id": "258479a613ae5bdf",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training",
   "id": "55e411c3bb76aed8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:07:21.762010Z",
     "start_time": "2025-03-03T20:07:21.758826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mse_loss(predictions, targets):\n",
    "    \"\"\"\n",
    "    Compute Mean Squared Error loss in JAX.\n",
    "\n",
    "    Args:\n",
    "        predictions: The model predictions\n",
    "        targets: The ground truth targets\n",
    "\n",
    "    Returns:\n",
    "        The mean squared error loss\n",
    "    \"\"\"\n",
    "    squared_error = jnp.square(predictions - targets)\n",
    "    return jnp.mean(squared_error)"
   ],
   "id": "1ccaed08c212c6d8",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:31:18.159532Z",
     "start_time": "2025-03-03T20:31:18.148361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_loss(state, params, batch, dropout_key):\n",
    "    data, labels = batch\n",
    "    logits = state.apply_fn(params, data, rngs={'dropout': dropout_key})\n",
    "\n",
    "    loss = mse_loss(logits, labels)\n",
    "    return loss"
   ],
   "id": "62a8ce2cd430f35f",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:31:19.289930Z",
     "start_time": "2025-03-03T20:31:19.286070Z"
    }
   },
   "cell_type": "code",
   "source": "grad_fn = jax.value_and_grad(calculate_loss, argnums=1)",
   "id": "6e8b7830535a2169",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:31:19.495649Z",
     "start_time": "2025-03-03T20:31:19.489544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch, dropout_key):\n",
    "    loss, grads = grad_fn(state, state.params, batch, dropout_key)\n",
    "    new_state = state.apply_gradients(grads=grads)\n",
    "    return new_state, loss"
   ],
   "id": "f746d92eca6ebea7",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:31:20.180633Z",
     "start_time": "2025-03-03T20:31:20.153849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the embedding layer\n",
    "token_embedding_layer = nn.Embed(tokenizer.vocab_size, emb_size)\n",
    "\n",
    "# Initialize the layer with random parameters\n",
    "embedding_params = token_embedding_layer.init(random.PRNGKey(0), test_encoded['input_ids'][0])\n",
    "\n",
    "# Apply the layer with the initialized parameters\n",
    "embedding_output = token_embedding_layer.apply(embedding_params, test_encoded['input_ids'][0])\n",
    "\n",
    "# Now you can check the shape\n",
    "print(embedding_output.shape)"
   ],
   "id": "c1c8ef68deb46c41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 384)\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:31:20.532357Z",
     "start_time": "2025-03-03T20:31:20.530222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_iters = 500\n",
    "eval_interval = 10\n",
    "lossi = []\n"
   ],
   "id": "b5f6ab24932fa5ee",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T20:31:29.028091Z",
     "start_time": "2025-03-03T20:31:21.436079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(max_iters):\n",
    "    dropout_key, subkey1, subkey2 = random.split(dropout_key, 3)\n",
    "    random_line1, random_line2 = get_sample(subkey1)\n",
    "    y = concatenate_and_adjust(random_line1, random_line2)\n",
    "\n",
    "    x, mask = masker(y, subkey2)\n",
    "    x_b = jnp.expand_dims(x, axis=0)\n",
    "\n",
    "    labels = token_embedding_layer.apply(embedding_params, y) + token_embedding_layer.apply(embedding_params, jnp.arange(seq_len))\n",
    "    emb_labels = jnp.expand_dims(labels, axis=0)\n",
    "\n",
    "    state, loss = train_step(model_state, (x_b, emb_labels), dropout_key)\n",
    "    lossi.append(loss)\n",
    "    if i % eval_interval == 0:\n",
    "        print(f'Step {i}: Loss {loss}')\n",
    "        eval_loss = calculate_loss(state, state.params, (x_b, emb_labels), dropout_key)\n",
    "        print(f'Eval loss: {eval_loss}')"
   ],
   "id": "ca3b91cd1ec9e0a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Loss 7.392397403717041\n",
      "Eval loss: 8.958538055419922\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot broadcast to shape with fewer dimensions: arr_shape=(1,) shape=()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[99], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m random_line1, random_line2 \u001B[38;5;241m=\u001B[39m get_sample(subkey1)\n\u001B[1;32m      4\u001B[0m y \u001B[38;5;241m=\u001B[39m concatenate_and_adjust(random_line1, random_line2)\n\u001B[0;32m----> 6\u001B[0m x, mask \u001B[38;5;241m=\u001B[39m \u001B[43mmasker\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubkey2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m x_b \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39mexpand_dims(x, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      9\u001B[0m labels \u001B[38;5;241m=\u001B[39m token_embedding_layer\u001B[38;5;241m.\u001B[39mapply(embedding_params, y) \u001B[38;5;241m+\u001B[39m token_embedding_layer\u001B[38;5;241m.\u001B[39mapply(embedding_params, jnp\u001B[38;5;241m.\u001B[39marange(seq_len))\n",
      "Cell \u001B[0;32mIn[58], line 14\u001B[0m, in \u001B[0;36mmasker\u001B[0;34m(encoded_text, key)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Replace with a random token 10% of the time\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m jax\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39muniform(subkey2, minval\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, maxval\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0.9\u001B[39m:\n\u001B[0;32m---> 14\u001B[0m     masked_input_ids \u001B[38;5;241m=\u001B[39m \u001B[43mmasked_input_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mat\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandint\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubkey2\u001B[49m\u001B[43m,\u001B[49m\u001B[43mshape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mminval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvocab_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Keep the original word 10% of the time\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/Implementation/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:798\u001B[0m, in \u001B[0;36m_IndexUpdateRef.set\u001B[0;34m(self, values, indices_are_sorted, unique_indices, mode)\u001B[0m\n\u001B[1;32m    789\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mset\u001B[39m(\u001B[38;5;28mself\u001B[39m, values, \u001B[38;5;241m*\u001B[39m, indices_are_sorted\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, unique_indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    790\u001B[0m         mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    791\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Pure equivalent of ``x[idx] = y``.\u001B[39;00m\n\u001B[1;32m    792\u001B[0m \n\u001B[1;32m    793\u001B[0m \u001B[38;5;124;03m  Returns the value of ``x`` that would result from the NumPy-style\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    796\u001B[0m \u001B[38;5;124;03m  See :mod:`jax.ops` for details.\u001B[39;00m\n\u001B[1;32m    797\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 798\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mscatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_scatter_update\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlax\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mindices_are_sorted\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindices_are_sorted\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43munique_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munique_indices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/Implementation/lib/python3.12/site-packages/jax/_src/ops/scatter.py:77\u001B[0m, in \u001B[0;36m_scatter_update\u001B[0;34m(x, idx, y, scatter_op, indices_are_sorted, unique_indices, mode, normalize_indices)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;66;03m# XLA gathers and scatters are very similar in structure; the scatter logic\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;66;03m# is more or less a transpose of the gather equivalent.\u001B[39;00m\n\u001B[1;32m     76\u001B[0m treedef, static_idx, dynamic_idx \u001B[38;5;241m=\u001B[39m indexing\u001B[38;5;241m.\u001B[39msplit_index_for_jit(idx, x\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m---> 77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_scatter_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscatter_op\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtreedef\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstatic_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdynamic_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mindices_are_sorted\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munique_indices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mnormalize_indices\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/Implementation/lib/python3.12/site-packages/jax/_src/ops/scatter.py:112\u001B[0m, in \u001B[0;36m_scatter_impl\u001B[0;34m(x, y, scatter_op, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, normalize_indices)\u001B[0m\n\u001B[1;32m    109\u001B[0m x, y \u001B[38;5;241m=\u001B[39m promote_dtypes(x, y)\n\u001B[1;32m    111\u001B[0m \u001B[38;5;66;03m# Broadcast `y` to the slice output shape.\u001B[39;00m\n\u001B[0;32m--> 112\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[43mjnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbroadcast_to\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mindexer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mslice_shape\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;66;03m# Collapse any `None`/`np.newaxis` dimensions.\u001B[39;00m\n\u001B[1;32m    114\u001B[0m y \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39msqueeze(y, axis\u001B[38;5;241m=\u001B[39mindexer\u001B[38;5;241m.\u001B[39mnewaxis_dims)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/Implementation/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:3139\u001B[0m, in \u001B[0;36mbroadcast_to\u001B[0;34m(array, shape)\u001B[0m\n\u001B[1;32m   3104\u001B[0m \u001B[38;5;129m@export\u001B[39m\n\u001B[1;32m   3105\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mbroadcast_to\u001B[39m(array: ArrayLike, shape: DimSize \u001B[38;5;241m|\u001B[39m Shape) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Array:\n\u001B[1;32m   3106\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Broadcast an array to a specified shape.\u001B[39;00m\n\u001B[1;32m   3107\u001B[0m \n\u001B[1;32m   3108\u001B[0m \u001B[38;5;124;03m  JAX implementation of :func:`numpy.broadcast_to`. JAX uses NumPy-style\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3137\u001B[0m \u001B[38;5;124;03m  .. _NumPy broadcasting: https://numpy.org/doc/stable/user/basics.broadcasting.html\u001B[39;00m\n\u001B[1;32m   3138\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3139\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_broadcast_to\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/Implementation/lib/python3.12/site-packages/jax/_src/numpy/util.py:269\u001B[0m, in \u001B[0;36m_broadcast_to\u001B[0;34m(arr, shape, sharding)\u001B[0m\n\u001B[1;32m    267\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m arr\n\u001B[1;32m    268\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(shape) \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(arr_shape):\n\u001B[0;32m--> 269\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot broadcast to shape with fewer dimensions: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00marr_shape\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mshape\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    270\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    271\u001B[0m   nlead \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(shape) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mlen\u001B[39m(arr_shape)\n",
      "\u001B[0;31mValueError\u001B[0m: Cannot broadcast to shape with fewer dimensions: arr_shape=(1,) shape=()"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c1490acf9bbe57cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
