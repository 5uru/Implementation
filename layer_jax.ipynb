{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-23T18:23:19.698172Z",
     "start_time": "2025-02-23T18:23:19.692074Z"
    }
   },
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T19:22:12.188249Z",
     "start_time": "2025-02-23T19:22:12.184619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Activation functions\n",
    "def relu(input):\n",
    "    return jnp.maximum(0, input)\n",
    "\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    x_max = jnp.max(x, axis=axis, keepdims=True)\n",
    "    x_shifted = x - x_max\n",
    "    exp_x = jnp.exp(x_shifted)\n",
    "    return exp_x / jnp.sum(exp_x, axis=axis, keepdims=True)\n",
    "\n",
    "def sigmoid(x): 1 / (1 + jnp.exp(-x))"
   ],
   "id": "7bea12dd7bfa1ad2",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T19:22:12.697485Z",
     "start_time": "2025-02-23T19:22:12.694378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dense Layer\n",
    "\n",
    "def initialize_dense_layer(key, input_dim, output_dim):\n",
    "    w_key, b_key = random.split(key)\n",
    "    # Xavier uniform limit for W and b\n",
    "    limit = jnp.sqrt(6.0/(input_dim + output_dim))\n",
    "\n",
    "    # Xavier uniform initialization for weights and biases\n",
    "    w = random.uniform(w_key, (input_dim, output_dim), minval=-limit, maxval=limit)\n",
    "    b = random.uniform(b_key, (output_dim,), minval=-limit, maxval=limit)\n",
    "    return w, b\n",
    "\n",
    "def dense_layer(params, x):\n",
    "    w, b = params\n",
    "    return jnp.dot(x, w) + b"
   ],
   "id": "4314253452b9f1b7",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T19:22:12.879149Z",
     "start_time": "2025-02-23T19:22:12.872435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the dense layer\n",
    "key = random.PRNGKey(0)\n",
    "input_dim = 10\n",
    "output_dim = 5\n",
    "\n",
    "params = initialize_dense_layer(key, input_dim, output_dim)\n",
    "x = jnp.ones((input_dim,))\n",
    "y = dense_layer(params, x)\n",
    "print(y)"
   ],
   "id": "6445ce4922c627ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.2890662   0.866141    1.8838954   0.77692413 -1.1997658 ]\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T19:22:13.281031Z",
     "start_time": "2025-02-23T19:22:13.278278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Layer normalization\n",
    "\n",
    "def initialize_layer_norm(hidden_dim):\n",
    "    gamma = jnp.ones(hidden_dim)\n",
    "    beta = jnp.zeros(hidden_dim)\n",
    "    return gamma, beta\n",
    "\n",
    "def layer_norm(x, layernorm_params):\n",
    "    # a simple layer norm\n",
    "    gamma, beta = layernorm_params\n",
    "    mean = jnp.mean(x, axis=-1, keepdims=True)\n",
    "    var = jnp.var(x, axis=-1, keepdims=True)\n",
    "    return gamma * (x - mean) / jnp.sqrt(var + 1e-6) + beta\n",
    "\n"
   ],
   "id": "bf06e11d2c1bdc74",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T19:22:13.586118Z",
     "start_time": "2025-02-23T19:22:13.581044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the layer norm\n",
    "hidden_dim = 10\n",
    "layernorm_params = initialize_layer_norm(hidden_dim)\n",
    "x = jnp.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "y = layer_norm(x, layernorm_params)\n",
    "print(y)"
   ],
   "id": "f487e694266e0823",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.5666988  -1.2185435  -0.8703882  -0.52223295 -0.17407764  0.17407764\n",
      "  0.52223295  0.8703882   1.2185435   1.5666988 ]\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T19:22:13.795170Z",
     "start_time": "2025-02-23T19:22:13.792701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MLP\n",
    "def initialize_mlp(hidden_dim, mlp_dim, key):\n",
    "    w1_key, w2_key = random.split(key)\n",
    "\n",
    "    # Xavier uniform limit for w1 and w2\n",
    "    limit = jnp.sqrt(6.0 / (hidden_dim + mlp_dim))\n",
    "\n",
    "    # Xavier uniform initialization for weights\n",
    "    w1 = random.uniform(w1_key, (hidden_dim, mlp_dim), minval=-limit, maxval=limit)\n",
    "    b1 = jnp.zeros(mlp_dim)\n",
    "\n",
    "    w2 = random.uniform(w2_key, (mlp_dim, hidden_dim), minval=-limit, maxval=limit)\n",
    "    b2 = jnp.zeros(hidden_dim)\n",
    "\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "def mlp(x, mlp_params):\n",
    "\n",
    "    # unpack the parameters\n",
    "    w1, b1, w2, b2 = mlp_params\n",
    "\n",
    "    # out = (Relu(x*w1 + b1))*w2 + b2\n",
    "    up_proj = relu(jnp.matmul(x, w1) + b1)\n",
    "    down_proj = jnp.matmul(up_proj, w2) + b2\n",
    "\n",
    "    return down_proj"
   ],
   "id": "66bbedc98b687f24",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T19:22:13.898693Z",
     "start_time": "2025-02-23T19:22:13.894324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the MLP\n",
    "hidden_dim = 10\n",
    "mlp_dim = 5\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "params = initialize_mlp(hidden_dim, mlp_dim, key)\n",
    "x = jnp.ones((hidden_dim,))\n",
    "y = mlp(x, params)\n",
    "print(y)"
   ],
   "id": "39c8b45af951de7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.45543894 -0.27045643 -0.08839004  0.02056309 -1.2242546   0.6535751\n",
      " -1.611247   -0.48521277  1.2017834  -0.7943954 ]\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T19:22:14.069614Z",
     "start_time": "2025-02-23T19:22:14.066038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Self-attention\n",
    "head_dim = 64\n",
    "num_heads = 4\n",
    "\n",
    "def initialize_attention(hidden_dim, num_heads,head_dim, key):\n",
    "    q_key, k_key, v_key = random.split(key, 3)\n",
    "\n",
    "    # Limit for Xavier uniform\n",
    "    fan_in = hidden_dim\n",
    "    fan_out = head_dim * num_heads\n",
    "    limit = jnp.sqrt(6.0 / (fan_in + fan_out))\n",
    "\n",
    "    # Random weights from uniform distribution\n",
    "    q_w = random.uniform(q_key, (fan_in, fan_out), minval=-limit, maxval=limit)\n",
    "    q_b = jnp.zeros(fan_out)\n",
    "    k_w = random.uniform(k_key, (fan_in, fan_out), minval=-limit, maxval=limit)\n",
    "    k_b = jnp.zeros(fan_out)\n",
    "    v_w = random.uniform(v_key, (fan_in, fan_out), minval=-limit, maxval=limit)\n",
    "    v_b = jnp.zeros(fan_out)\n",
    "\n",
    "    return q_w, k_w, v_w, q_b, k_b, v_b\n",
    "\n",
    "\n",
    "def self_attention(x, attn_params):\n",
    "\n",
    "    # unpack the parameters\n",
    "    q_w, k_w, v_w, q_b, k_b, v_b = attn_params\n",
    "\n",
    "    # n and d_k are the sequence length of the input and the hidden dimension\n",
    "    n, d_k = x.shape\n",
    "\n",
    "    # project the input into the query, key and value spaces\n",
    "    q = jnp.matmul(x, q_w) + q_b\n",
    "    k = jnp.matmul(x, k_w) + k_b\n",
    "    v = jnp.matmul(x, v_w) + v_b\n",
    "\n",
    "\n",
    "    # reshape to have heads\n",
    "    # n, (num_heads head_dim) ->  (n, num_heads, headim) -> (num_heads, n, head_dim)\n",
    "    q = q.reshape(n, num_heads, head_dim).swapaxes(0, 1)\n",
    "    k = k.reshape(n, num_heads, head_dim).swapaxes(0, 1)\n",
    "    v = v.reshape(n, num_heads, head_dim).swapaxes(0, 1)\n",
    "\n",
    "    # perform multi-head attention\n",
    "    attention_weights_heads = jnp.matmul(q, jnp.swapaxes(k, -1, -2)) / jnp.sqrt(head_dim)\n",
    "    attention_weights_heads = jax.nn.softmax(attention_weights_heads, axis=-1)\n",
    "\n",
    "    # output projection (num_heads, n, head_dim)\n",
    "    output = jnp.matmul(attention_weights_heads, v)\n",
    "\n",
    "    # reshape back (n, num_heads * heam_dim)\n",
    "    output = output.swapaxes(0,1).reshape(n, d_k)\n",
    "\n",
    "    return output\n"
   ],
   "id": "2dcaff488625ac92",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T19:24:27.518993Z",
     "start_time": "2025-02-23T19:24:27.512678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Embedding\n",
    "def initialize_embedding(key, vocab_size, hidden_dim):\n",
    "    limit = jnp.sqrt(6.0 / (vocab_size + hidden_dim))\n",
    "    w_key = random.split(key)[0]\n",
    "    w = random.uniform(w_key, (vocab_size, hidden_dim), minval=-limit, maxval=limit)\n",
    "    return w\n",
    "\n",
    "def embedding(x, embedding_params):\n",
    "    return embedding_params[x]"
   ],
   "id": "a80fa161909bc359",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T19:24:34.010244Z",
     "start_time": "2025-02-23T19:24:33.849896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the embedding\n",
    "key = random.PRNGKey(0)\n",
    "vocab_size = 10\n",
    "hidden_dim = 5\n",
    "\n",
    "params = initialize_embedding(key, vocab_size, hidden_dim)\n",
    "x = jnp.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "y = embedding(x, params)\n",
    "print(y)"
   ],
   "id": "b196b018ff607893",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.43925422  0.09296543  0.01709316 -0.38812086  0.17173995]\n",
      " [ 0.58346367  0.42921904  0.4783264   0.46378067 -0.04329202]\n",
      " [-0.48244128  0.14456141  0.53700733  0.07577622 -0.523541  ]\n",
      " [-0.47330436 -0.08072075  0.02309517  0.5157007   0.04450391]\n",
      " [ 0.07960355  0.52857083 -0.52578     0.21598057 -0.6159274 ]\n",
      " [ 0.28318474  0.37144148  0.1625991   0.24843854  0.40760177]\n",
      " [-0.16007414  0.58533496  0.45814523 -0.27706602  0.41568798]\n",
      " [ 0.4229473  -0.5099719   0.15901892  0.36687768 -0.48541275]\n",
      " [ 0.43236148 -0.31739697  0.44400045 -0.58978945 -0.21325506]\n",
      " [-0.2950449   0.2288812  -0.47637233 -0.33364934  0.06641433]]\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T19:54:40.735213Z",
     "start_time": "2025-02-23T19:54:40.728088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dropout\n",
    "def dropout(key, x, rate, in_train_mode = True):\n",
    "    if in_train_mode:\n",
    "        mask = random.bernoulli(key, rate, x.shape)\n",
    "        return x * mask / (1.0 - rate)\n",
    "    return x"
   ],
   "id": "d333a99e8b8dea55",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T19:54:40.955193Z",
     "start_time": "2025-02-23T19:54:40.947617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the dropout\n",
    "key = random.PRNGKey(0)\n",
    "x = jnp.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "rate = 0.5\n",
    "y = dropout(key, x, rate)\n",
    "print(y)"
   ],
   "id": "bd9f523bf468a449",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  0.  6.  8. 10. 12. 14. 16.  0.  0.]\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T19:39:54.882409Z",
     "start_time": "2025-02-23T19:39:54.875918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Batch Normalization Layer\n",
    "def initialize_batch_norm(hidden_dim):\n",
    "    gamma = jnp.ones(hidden_dim)\n",
    "    beta = jnp.zeros(hidden_dim)\n",
    "\n",
    "    running_mean = jnp.zeros(hidden_dim)\n",
    "    running_var = jnp.ones(hidden_dim)\n",
    "    return gamma, beta, running_mean, running_var\n",
    "\n",
    "def batch_norm(params, inputs, train_mode=True, epsilon=1e-6, momentum=0.9):\n",
    "    gamma, beta, running_mean, running_var = params\n",
    "    if train_mode:\n",
    "        mean = jnp.mean(inputs, axis=0)\n",
    "        var = jnp.var(inputs, axis=0)\n",
    "        running_mean = momentum * running_mean + (1.0 - momentum) * mean\n",
    "        running_var = momentum * running_var + (1.0 - momentum) * var\n",
    "\n",
    "        # Normalize the inputs\n",
    "        x_hat = (inputs - mean) / jnp.sqrt(var + epsilon)\n",
    "        return gamma * x_hat + beta\n",
    "    else:\n",
    "        x_hat = (inputs - running_mean) / jnp.sqrt(running_var + epsilon)\n",
    "        return gamma * x_hat + beta\n",
    "\n"
   ],
   "id": "8c4496b2d33cdc15",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T19:40:03.897690Z",
     "start_time": "2025-02-23T19:40:03.706398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the batch norm\n",
    "hidden_dim = 10\n",
    "batch_norm_params = initialize_batch_norm(hidden_dim)\n",
    "x = jnp.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "y = batch_norm(batch_norm_params, x)\n",
    "print(y)"
   ],
   "id": "6114a328d7ad9c7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.5666988  -1.2185435  -0.8703882  -0.52223295 -0.17407764  0.17407764\n",
      "  0.52223295  0.8703882   1.2185435   1.5666988 ]\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e7ab3d5f9d3e7a4d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
